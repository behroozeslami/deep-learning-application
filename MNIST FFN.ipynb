{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92036656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c49698e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b7dac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784        #Number of input neurons (image pixels)\n",
    "hidden_size = 400       #Number of hidden neurons\n",
    "out_size = 10           #Number of classes (0-9) \n",
    "epochs = 10            #How many times we pass our entire dataset into our network \n",
    "batch_size = 100        #Input size of the data during one iteration \n",
    "learning_rate = 0.001   #How fast we are learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba0fbc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa11c55b025f4fa680319db353f1c14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe45be944444354b98ed41d67eeda0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc98584705142b6950f0d35205ea5a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a49c531a53458c85746957c3f93301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST(root='./data',\n",
    "                           train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79067a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPGElEQVR4nO3df4xc5XXG8eeJbUwxJthxbBziggNOgEBj0pUBGQFVFEJQJUAVEAtFDqV1muCktK4EpVWhFW3dKiEihCKZ4mIqficgLJWSICuFpA0uCzVgfoNxibFrY7ZgIOAf69M/dlwtsPPueubu3PGe70cazcw9c+cejf3snZn33nkdEQIw9n2k7gYAdAZhB5Ig7EAShB1IgrADSRB2IAnCDiRB2DEk2/9m+z3bbzcuz9XdE9pD2FGyOCIObFw+U3czaA9hB5Ig7Cj5W9tbbf+77dPqbgbtMcfGYyi2T5D0tKQdkr4i6QeS5kbES7U2hpYRdoyI7fsl/UtEXFt3L2gNb+MxUiHJdTeB1hF2fIjtg21/yfb+tsfbvkDSKZJ+XHdvaN34uhtAV5og6SpJR0nql/SspLMjgrH2fRif2YEkeBsPJEHYgSQIO5AEYQeS6Oi38ft5YuyvSZ3cJJDKe3pHO2L7kMdDtBV222dIukbSOEn/GBFLS4/fX5N0gr/QziYBFKyOVU1rLb+Ntz1O0nWSvizpGEkLbB/T6vMBGF3tfGafJ+nFiFgXETsk3S7prGraAlC1dsJ+qKRfDrq/obHsfWwvst1ru3entrexOQDtaCfsQ30J8KHD8SJiWUT0RETPBE1sY3MA2tFO2DdImjXo/iclbWyvHQCjpZ2wPyJpju3ZtvfTwA8crKymLQBVa3noLSJ22V6sgdMex0laHhFPVdYZgEq1Nc4eEfdJuq+iXgCMIg6XBZIg7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IIm2ZnFF9/P48j/xuI9PG9XtP/cnhzet9R+wu7juYUdsKdYP+KaL9f+5er+mtcd67iiuu7X/nWL9hLuWFOtH/vHDxXod2gq77fWS3pLUL2lXRPRU0RSA6lWxZ/+tiNhawfMAGEV8ZgeSaDfsIeknth+1vWioB9heZLvXdu9ObW9zcwBa1e7b+PkRsdH2dEkP2H42Ih4a/ICIWCZpmSQd5KnR5vYAtKitPXtEbGxcb5F0j6R5VTQFoHoth932JNuT99yWdLqktVU1BqBa7byNnyHpHtt7nufWiLi/kq7GmHFHzynWY+KEYn3jqQcX6++e2HxMeOpHy+PFP/tceby5Tv/6q8nF+t/94IxiffVxtzatvbzz3eK6Szd/sVj/xM/2vU+kLYc9ItZJ+lyFvQAYRQy9AUkQdiAJwg4kQdiBJAg7kASnuFag/7TPF+tX33Rdsf7pCc1PxRzLdkZ/sf4X136tWB//Tnn466S7FjetTX51V3HdiVvLQ3MH9K4u1rsRe3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9gpMfG5jsf7oe7OK9U9P2FxlO5VasunEYn3d2+Wfor7piB82rb25uzxOPuP7/1Gsj6Z97wTW4bFnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkHNG5EcWDPDVO8Bc6tr1u0XfhScX6tjPKP/c87okDi/XHv3ntXve0x1Vbf6NYf+TU8jh6/xtvFutxUvMfIF7/7eKqmr3g8fID8CGrY5W2Rd+Qc1mzZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhn7wLjpn2sWO9/va9Yf/nW5mPlT52yvLjuvL/5VrE+/br6zinH3mtrnN32cttbbK8dtGyq7Qdsv9C4nlJlwwCqN5K38TdJ+uCs95dJWhURcyStatwH0MWGDXtEPCTpg+8jz5K0onF7haSzq20LQNVa/YJuRkRskqTG9fRmD7S9yHav7d6d2t7i5gC0a9S/jY+IZRHRExE9EzRxtDcHoIlWw77Z9kxJalxvqa4lAKOh1bCvlLSwcXuhpHuraQfAaBn2d+Nt3ybpNEnTbG+QdIWkpZLutH2RpFcknTuaTY51/Vtfb2v9ndtan9/9sxc8Xay/dv248hPsLs+xju4xbNgjYkGTEkfHAPsQDpcFkiDsQBKEHUiCsANJEHYgCaZsHgOOvvT5prULjysPmvzTYauK9VPPvbhYn3zHw8U6ugd7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2MaA0bfLr3zi6uO4rK98t1i+76uZi/U/PO6dYj//6aNParL/+RXFddfBnzjNgzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTBlc3J9v3tSsX7LFd8p1meP37/lbX/25sXF+pwbNhXru9atb3nbY1VbUzYDGBsIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlRFPPnFusHLd1QrN/2qR+3vO2jfvp7xfpn/rL5efyS1P/Cupa3va9qa5zd9nLbW2yvHbTsStuv2l7TuJxZZcMAqjeSt/E3STpjiOXfi4i5jct91bYFoGrDhj0iHpLU14FeAIyidr6gW2z7icbb/CnNHmR7ke1e2707tb2NzQFoR6thv17SEZLmStok6bvNHhgRyyKiJyJ6Jmhii5sD0K6Wwh4RmyOiPyJ2S7pB0rxq2wJQtZbCbnvmoLvnSFrb7LEAusOw4+y2b5N0mqRpkjZLuqJxf66kkLRe0tcjonzysRhnH4vGzZherG88/8imtdWXXlNc9yPD7IsuePn0Yv3Nk18v1sei0jj7sJNERMSCIRbf2HZXADqKw2WBJAg7kARhB5Ig7EAShB1IglNcUZs7N5SnbD7A+xXrv4odxfpvf+uS5s99z+riuvsqfkoaAGEHsiDsQBKEHUiCsANJEHYgCcIOJDHsWW/IbffJc4v1l84tT9l87Nz1TWvDjaMP59q+44v1A+7tbev5xxr27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsY5x7ji3Wn/92eaz7hvkrivVT9i+fU96O7bGzWH+4b3b5CXYP++vmqbBnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkhh1ntz1L0s2SDpG0W9KyiLjG9lRJd0g6XAPTNp8XEf87eq3mNX72YcX6Sxd+omntyvNvL677OwdubamnKly+uadYf/CaE4v1KSvKvzuP9xvJnn2XpCURcbSkEyVdbPsYSZdJWhURcyStatwH0KWGDXtEbIqIxxq335L0jKRDJZ0lac/hVSsknT1KPQKowF59Zrd9uKTjJa2WNCMiNkkDfxAkTa+8OwCVGXHYbR8o6UeSLomIbXux3iLbvbZ7d2p7Kz0CqMCIwm57ggaCfktE3N1YvNn2zEZ9pqQtQ60bEcsioicieiZoYhU9A2jBsGG3bUk3SnomIq4eVFopaWHj9kJJ91bfHoCqjOQU1/mSvirpSdtrGssul7RU0p22L5L0iqRzR6XDMWD84b9erL/5mzOL9fP/6v5i/Q8OvrtYH01LNpWHx37xD82H16be9J/FdafsZmitSsOGPSJ+LmnI+Z4lMdk6sI/gCDogCcIOJEHYgSQIO5AEYQeSIOxAEvyU9AiNn3lI01rf8knFdb8x+8FifcHkzS31VIXFr55crD92/dxifdoP1xbrU99irLxbsGcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSTSjLPv+FL5Z4t3/FFfsX75kfc1rZ3+a++01FNVNve/27R2ysolxXWP+vNni/Wpb5THyXcXq+gm7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIk04+zrzy7/XXv+uLtGbdvXvXFEsX7Ng6cX6+5v9kveA4666uWmtTmbVxfX7S9WMZawZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBwR5QfYsyTdLOkQDZy+vCwirrF9paTfl/Ra46GXR0Tzk74lHeSpcYKZ5RkYLatjlbZF35AHZozkoJpdkpZExGO2J0t61PYDjdr3IuI7VTUKYPQMG/aI2CRpU+P2W7afkXToaDcGoFp79Znd9uGSjpe05xjMxbafsL3c9pQm6yyy3Wu7d6e2t9ctgJaNOOy2D5T0I0mXRMQ2SddLOkLSXA3s+b871HoRsSwieiKiZ4Imtt8xgJaMKOy2J2gg6LdExN2SFBGbI6I/InZLukHSvNFrE0C7hg27bUu6UdIzEXH1oOUzBz3sHEnl6TwB1Gok38bPl/RVSU/aXtNYdrmkBbbnSgpJ6yV9fRT6A1CRkXwb/3NJQ43bFcfUAXQXjqADkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kMexPSVe6Mfs1Sf89aNE0SVs71sDe6dbeurUvid5aVWVvh0XEx4cqdDTsH9q43RsRPbU1UNCtvXVrXxK9tapTvfE2HkiCsANJ1B32ZTVvv6Rbe+vWviR6a1VHeqv1MzuAzql7zw6gQwg7kEQtYbd9hu3nbL9o+7I6emjG9nrbT9peY7u35l6W295ie+2gZVNtP2D7hcb1kHPs1dTblbZfbbx2a2yfWVNvs2z/1PYztp+y/YeN5bW+doW+OvK6dfwzu+1xkp6X9EVJGyQ9ImlBRDzd0UaasL1eUk9E1H4Ahu1TJL0t6eaIOLax7O8l9UXE0sYfyikRcWmX9HalpLfrnsa7MVvRzMHTjEs6W9LXVONrV+jrPHXgdatjzz5P0osRsS4idki6XdJZNfTR9SLiIUl9H1h8lqQVjdsrNPCfpeOa9NYVImJTRDzWuP2WpD3TjNf62hX66og6wn6opF8Our9B3TXfe0j6ie1HbS+qu5khzIiITdLAfx5J02vu54OGnca7kz4wzXjXvHatTH/erjrCPtRUUt00/jc/Ij4v6cuSLm68XcXIjGga704ZYprxrtDq9OftqiPsGyTNGnT/k5I21tDHkCJiY+N6i6R71H1TUW/eM4Nu43pLzf38v26axnuoacbVBa9dndOf1xH2RyTNsT3b9n6SviJpZQ19fIjtSY0vTmR7kqTT1X1TUa+UtLBxe6Gke2vs5X26ZRrvZtOMq+bXrvbpzyOi4xdJZ2rgG/mXJP1ZHT006etTkh5vXJ6quzdJt2ngbd1ODbwjukjSxyStkvRC43pqF/X2z5KelPSEBoI1s6beTtbAR8MnJK1pXM6s+7Ur9NWR143DZYEkOIIOSIKwA0kQdiAJwg4kQdiBJAg7kARhB5L4P95YpoYa8Z3+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[0][0][0])\n",
    "plt.title(train_dataset[0][1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0784058",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        torch.nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        torch.nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "211d0e81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model(input_size, hidden_size, out_size)\n",
    "\n",
    "if CUDA:\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Load the data to your dataloader for batch processing and shuffling\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a424d27a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.237, Training Accuracy: 93.152%\n",
      "Epoch [2/10], Training Loss: 0.084, Training Accuracy: 97.483%\n",
      "Epoch [3/10], Training Loss: 0.055, Training Accuracy: 98.223%\n",
      "Epoch [4/10], Training Loss: 0.038, Training Accuracy: 98.762%\n",
      "Epoch [5/10], Training Loss: 0.028, Training Accuracy: 99.077%\n",
      "Epoch [6/10], Training Loss: 0.021, Training Accuracy: 99.350%\n",
      "Epoch [7/10], Training Loss: 0.020, Training Accuracy: 99.278%\n",
      "Epoch [8/10], Training Loss: 0.017, Training Accuracy: 99.433%\n",
      "Epoch [9/10], Training Loss: 0.016, Training Accuracy: 99.437%\n",
      "Epoch [10/10], Training Loss: 0.012, Training Accuracy: 99.588%\n",
      "DONE TRAINING!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    correct_train = 0\n",
    "    running_loss = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(batch_size,-1)\n",
    "        if CUDA:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predictions = torch.max(outputs,1)\n",
    "        correct_train += (predictions == labels).sum()\n",
    "        running_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch [{}/{}], Training Loss: {:.3f}, Training Accuracy: {:.3f}%'.format\n",
    "          (epoch+1, epochs, running_loss/len(train_loader), (100*correct_train.double()/len(train_dataset))))\n",
    "    \n",
    "print(\"DONE TRAINING!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ba4c5716",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f5e02248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.01 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct_test = 0\n",
    "    for (images, labels) in test_loader:\n",
    "        images = images.view(batch_size,-1)\n",
    "        if CUDA:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs,1)\n",
    "        correct_test += (predictions == labels).sum().item()\n",
    "        \n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct_test / len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75a2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
